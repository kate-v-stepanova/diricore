

## UCSC link

http://genome-euro.ucsc.edu/cgi-bin/hgTracks?db=hg19&position=chr12:6643585-6647537&hubClear=http://ucsc:ucsc@156.35.56.116/~jandrulas/Fabricio/UCSC_Hub.txt


## Download data
````bash
wget --user-agent Mozilla/4.0 'https://download.wetransfer.com/eu2/bb156f95e9251cd8b27687bd0f23a33b20190124144712/ab9347b4ad4ddf9eea0966cc82446c12db97af7a/wetransfer-bb156f.zip?token=eyJhbGciOiJIUzI1NiJ9.eyJ1bmlxdWUiOiJiYjE1NmY5NWU5MjUxY2Q4YjI3Njg3YmQwZjIzYTMzYjIwMTkwMTI0MTQ0NzEyIiwicHJvZmlsZSI6ImV1MiIsImZpbGVuYW1lIjoid2V0cmFuc2Zlci1iYjE1NmYuemlwIiwiZXhwaXJlcyI6MTU0ODM1MDMwNywiaG90IjpmYWxzZSwiYnl0ZXNfZXN0aW1hdGVkIjo3NjU5OTE0ODAxLCJlbnRyaWVzX2ZpbmdlcnByaW50IjoiYWI5MzQ3YjRhZDRkZGY5ZWVhMDk2NmNjODI0NDZjMTJkYjk3YWY3YSIsImNhbGxiYWNrIjoie1wiZm9ybWRhdGFcIjp7XCJhY3Rpb25cIjpcImh0dHA6Ly9wcm9kdWN0aW9uLmZyb250ZW5kLnNlcnZpY2UuZXUtd2VzdC0xLnd0OjMwMDAvYXBpL2JhY2tlbmQvdHJhbnNmZXJzL2JiMTU2Zjk1ZTkyNTFjZDhiMjc2ODdiZDBmMjNhMzNiMjAxOTAxMjQxNDQ3MTIvZG93bmxvYWRzLzU0MDU2NjM0MjMvY29tcGxldGVkLzAzZDU4OGJjNDNiMWE4YWVjZWY5MjUwZDYxNzBlNDlmMjAxOTAxMjQxNDQ3MTJcIn0sXCJmb3JtXCI6e1wic3RhdHVzXCI6W1wicGFyYW1cIixcInN0YXR1c1wiXSxcImRvd25sb2FkX2lkXCI6XCI1NDA1NjYzNDIzXCJ9fSIsIndheWJpbGxfdXJsIjoiaHR0cDovL3Byb2R1Y3Rpb24uYmFja2VuZC5zZXJ2aWNlLmV1LXdlc3QtMS53dDo5MjkyL3dheWJpbGwvdjEvZDgzNTRlNzYxMTE4NjMyYzJmNDVhY2Y4M2UyZjBhYWIzMmRiZmQ5NTk3M2QyNzdlMDQzNTEzNDAwZTQyIn0.O3XZIXPLPuDu5iAuKFNkHwXjK7tvf897CVOTOMJ-0Rk&cf=y' -O data.zip
````

## Merge files

The facility attempted to demultiplex using the internal barcodes, but it failed. Anyway, I got the data split in multiple files, although most of the reads are in a "undertermined" file.
First, I combine all files in a single one:

````bash
cat *.gz > runUmis.fastq.gz
````


## Preprocessing
  This time Fabricio used a new protocol that employs circularization. Furthermore, the library contains UMIs to account for PCR duplicates.

  #### Trim adapters and barcode split
  In a first step, I remove the 3' adapter sequences using cutadapt. Furthermore, I trim 3 nt from the beginning that are introduced in the library construction (see [1-s2.0-S1046202316303292-gr1_lrg.jpg](1-s2.0-S1046202316303292-gr1_lrg.jpg)). Note that I filter out reads shorter than 30 nt (`-m 30`), which correspond to a ribosome protected fragment of 20nt plus 10nt containing the umi-bc.
  The output of cutadapt is piped to `fastx_barcode_splitter.pl` to split the data by barcode (without removing it).

  ````bash
  gzip -dc Data/runUmis.fastq.gz \
  | cutadapt -u 3 -O 7 -m 30 -a AGATCGGAAGAGCACACGTCTGAAX --discard-untrimmed - \
  2> Logs/cutadapt_trimming_stats.txt \
  | fastx_barcode_splitter.pl --bcfile Info_files/bc_file.txt --prefix Demultiplexed/run_umi_ --suffix .fastq --eol \
  2> Logs/bc_split_stats.txt
  ````

  NOTE: in retrospective, it would be safer to use the full adapter including the illumina primer, because I am forcing the adapter to be found at the end, not in the middle (note the X at the end of the adapter in the command). Anyway, we this run length (51nt), the reads that contain part of the illumina primer have by definition a too short protected fragment and are not useful. That means that I should use:
  AGATCGGAAGAGCACACGTCTGAA
              CACACGTCTGAACTCCAGTCACATCACGATCTCGTATGCCGTCTTCTGCTTG
  AGATCGGAAGAGCACACGTCTGAACTCCAGTCACATCACGATCTCGTATGCCGTCTTCTGCTTG


  #### Extract UMIs
  ````bash
  # Extract UMIs
  parallel -j 3 umi_tools extract --extract-method=string --3prime --bc-pattern=NNNNNNNNNN --stdin={} --log=Logs/{/.}_umiextract_stats.txt --stdout={.}_umied.fastq.gz --log2stderr ::: Demultiplexed/*.fastq
  # Delete the previous step
  rm Demultiplexed/*.fastq
  ````





## rRNA clean up
  Now I jump to the diricore pipeline. I copy the demultiplexed and umi-extracted files to the diricore input folder and run a modified preprocessing script. In this version (**run_umi_preprocessing.sh**), I removed all the cutadapt steps classically done in diricore and left just the rRNA and tRNA clean up steps.

  ````bash
  ./run_umi_preprocessing.sh human 2
  ````


## Alignment
  The alignment can be run normally using the diricore script
  ````bash
  ./run_alignment_parallel.sh human 1 2
  ````

## Deduplicate by UMI

  ````bash
  # Index the files (required for umi_tools)
  parallel -j 2 samtools index ::: */accepted_hits.hqmapped.bam
  # Dedup using umi tools
  parallel -j 2 umi_tools dedup --log2stderr -L umidedup_log.txt -I {} -S {.}_dedup.bam --output-stats=umidedup_stats.txt ::: */accepted_hits.hqmapped.bam
  ````

## RPF Density

````bash
# Using deduped data
  ./run_umi_rpf_density_analysis.sh human 20190123_Umi 15
# Using all hq algs
  ./run_rpf_density_analysis.sh human 20190123_allHQ 15
# Transfer data
  scp -r data/output/figures/rpf_5p_density_plots/ 156.35.56.111:/home/jandrulas/Sync/Uniovi_new/Fabricio/20190123_run/Plots/
````


## Subsequence analysis
````bash
# Create contrast from rpf_density_contrasts
  cut -f1,2 data/input/metadata/rpf_density_contrasts.tsv > data/input/metadata/subsequence_contrasts.tsv
  cp data/input/metadata/rpf_density_samplenames.tsv data/input/metadata/subsequence_samplenames.tsv
# Run analysis using deduped data
  ./run_umi_subsequence_analysis.sh human 20190123_Umi 25
# Using all hq algs
  ./run_subsequence_analysis.sh human 20190123_allHQ 25
# Transfer Data
  scp -r data/output/figures/subsequence_shift_plots/ 156.35.56.111:/home/jandrulas/Sync/Uniovi_new/Fabricio/20190123_run/Plots/
````

## RPF transcript distribution

````bash
# Using deduped algs
./plot_rpf_transcript_distribution.sh 20190123_Umi 25 20190123_Umi
# Using all hq reads
./plot_rpf_transcript_distribution.sh 20190123_allHQ 25 20190123_allHQ
````


## Get counts in genes for expression

We want to see the expression through RiboSeq. I could use diricore hd5f to do it, but I would have to implement the script and dig into the info. Instead, I will just use the filtered alignments to count reads in feature using htseq.
After long time using htseq, I just realized that if multiple files are provided, the scripts write it tabulated instead of combined.
Before running all samples, I tested which strandness parameter I should use (-s yes).

````bash
gtf='/home/jandrulas/Genome_Data/hg19/UCSC/gencode.v19.annotation.gtf.gz'
files=$(ls -1 data/output/tophat_out/*/accepted_hits.hqmapped_dedup.bam | tr '\n' ' ')
htseq-count -f bam -r pos -s yes -t exon -i gene_id \
--additional-attr gene_name gene_type -m union $files $gtf > htseq_counts.txt

# Add the header (NOTE the double quotes to pass var to sed)
# Note, the first step removes a trailing space
files=$(echo $files | sed 's/[[:blank:]]+$//')
header="Gene_id\tGene_name\tGene_type\t${files// /\\t}"
sed -i "1i$header" htseq_counts.txt
````

## Analyze counts in R

````r
require(data.table)
#Load
  dt <- fread('htseq_counts.txt')
# Fix colnames
  colnames(dt)[4:9] <- gsub('.*run_umi_(.*)_umied.*',"\\1",colnames(dt)[4:9])
# Filter stats
  dt <- dt[!grepl('^__', Gene_id)]
# Filter low counts
  dt <- dt[rowSums(dt[,4:9]) > 20]
# Filter coding genes
  dt <- dt[Gene_type == 'protein_coding']
# Normalize
  mycols <- colnames(dt)[4:9]
  dt[,(mycols):=lapply(.SD, function(x) x*100000/sum(x)),.SDcols=mycols]
# Write
  write.table(dt, 'run_UMIs_htseq_cpms_prot_cod.tsv', sep='\t',quote=F, row.names=F)

````

NOTE: I repeated this analysis using all the HQ algs (before deduping). I don't paste all the code, it is just repeat the same code changing the files used for input.


## Additional analysis

  ### Fragment size distribution for troubleshooting

    #### Get the fragment sizes
    ````bash
    gzip -dc Data/runUmis.fastq.gz \
    | cutadapt -u 3 -O 5 -a AGATCGGAAGAGCACACGTCTGAAX \
    --discard-untrimmed - 2> /dev/null \
    | fastq_to_fasta -Q33 | grep -v '^>' | awk '{print length}' \
    | sort | uniq -c | sed -e 's/^ \+//g' | tr ' ' '\t' \
    > run_UMIs_fragment_sizes.txt
    ````

    To have something to compare with, I do a similar analysis for a previous run using the classic riboseq protocol:

    ````bash
    gzip -dc 4867_6_YAP_E_NT_GCCAAT_S6_R1_001.fastq.gz \
    | cutadapt --quality-base=33 -a TGGAATTCTCGGGTGCCAAGGAACTCCAGTCACA \
    -O 7 -e 0.15 -q 5 --discard-untrimmed - 2> /dev/null \
    | cutadapt --quality-base=33 -a "GGCATTAACGCGAACTCGGCCTACAATAGT" \
    -a "AAGCGTGTACTCCGAAGAGGATCCAAA" -O 7 -e 0.15 - 2> /dev/null \
    | fastq_to_fasta -Q33 | grep -v '^>' | awk '{print length}' \
    | sort | uniq -c | sed -e 's/^ \+//g' | tr ' ' '\t' \
    > run_4867_fragment_sizes.txt
    ````

    #### Plot
      ````r
      setwd('Uniovi_new/Fabricio/20190123_run/')
      require(data.table)
      require(ggplot2)
      # This run
      mydt <- fread('Logs/run_UMIs_fragment_sizes.txt', col.names=c('Counts','Size'))
      mydt[Size >= 10, Size:=Size - 10L]
      mydt <- mydt[, .(Counts = sum(Counts)),  by=Size]

      myplot <- ggplot(mydt, aes(x=Size,y=Counts/1000000))
      myplot <- myplot + geom_bar(stat='identity',width=1, fill= '#4a7dc4',col='gray40')+
                theme_bw()+ylab('Million Reads')+
                xlab('Size of protected fragment (nt)')
      ggsave('Plots/Fragment_sizes.pdf', myplot)

      # A previous run (4867_6_YAP_E_NT_GCCAAT_S6_R1_001)
      mydt <- fread('Logs/run_4867_fragment_sizes.txt', col.names=c('Counts','Size'))
      myplot <- ggplot(mydt, aes(x=Size,y=Counts/1000000))
      myplot <- myplot + geom_bar(stat='identity',width=1, fill= '#4a7dc4',col='gray40')+
                theme_bw()+ylab('Million Reads')+
                xlab('Size of protected fragment (nt)')
      ggsave('Plots/run4867_Fragment_sizes.pdf', myplot)
      ````

  ### Plot alignment stats

    #### Collect stats about alignments
      ````bash
      # Get useful alignment number (HQ_aligns)
        ls */accepted_hits.hqmapped.bam \
        | while read inf; do
        c=$(samtools view -c $inf)
        echo -e "${inf}\t${c}"
      done >> ~/Fabricio/20190123_run/Logs/Alignment_hq_stats.txt

      # Get deduped alignment number
        ls */accepted_hits.hqmapped_dedup.bam \
        | while read inf; do
        c=$(samtools view -c $inf)
        echo -e "${inf}\t${c}"
      done >> ~/Fabricio/20190123_run/Logs/Alignment_dedup_stats.txt

      # Summarize MAPQ to get multimapper reads indirectly( MAPQ in 0,1,2,3)
        ls */accepted_hits.bam \
        | while read inf; do
        bn=$(dirname $inf)
        echo -e "Doing file $inf" >&2
        samtools view -F 0x100 $inf | awk '{print $5}' \
        | sort | uniq -c | sed "s/^/${bn} /"
        done >> ~/Fabricio/20190123_run/Logs/Alignment_multimap_stats.txt
      ````

    #### Collect RNAcleup info
      ````r
      require(data.table)

      myfiles <- list.files('data/output/clean/',
      full.names=T)
      names(myfiles) <- basename(myfiles)

      # Left after rrna and used for alignment
        sel <- myfiles[grepl('*trna.err',myfiles)]
        dt <- do.call('rbind',
          lapply(sel, function(x){
          x <- readLines(x)
          data.table('rrnaleft' = as.numeric(gsub('([0-9]+).*',"\\1",x[1])),
                      'trnaleft' = as.numeric(gsub('([0-9]+).*',"\\1",x[3])))
        }))
        dt$file = gsub('\\.trna\\.err',"",basename(sel))

      write.table(dt, '~/Fabricio/20190123_run/Logs/RNA_cleup_stats.txt',
      quote=F, row.names=F, sep='\t')
      ````

    #### Make plots with stats

      ````r
      setwd('Uniovi_new/Fabricio/20190123_run/')

      require(ggplot2)
      require(data.table)

      # Manually input data from Logs/cutadapt_trimming_stats.txt
        mydt <- data.table(
          'Reads' = c('No_adapt','Too_short','Passed'),
          'Counts' = c(263519465-233487367, 140206555,93280812))

        myplot <- ggplot(mydt,aes(x='run_umis',y=Counts/1000000, fill=Reads))
        myplot <- myplot + geom_bar(stat='identity',position='stack')+
          theme_bw()+xlab(NULL)+ ylab('Million reads')
        ggsave('Plots/Cutadapt_stats.pdf',myplot,width = 2.5,height = 4)

      # BC stats
        require(RColorBrewer)
        mydt <- fread('Logs/bc_split_stats.txt',fill=T)
        mydt <- mydt[1:nrow(mydt) -1]

        myplot <- ggplot(mydt, aes(x='run_umis', y=Count/1000000, fill=Barcode))
        myplot <- myplot + geom_bar(stat='identity',position='stack')+
                    scale_fill_manual(values=c(brewer.pal(6,'Set3'),'gray30'))+
                    xlab(NULL) + ylab('Million reads') + theme_bw()
        ggsave('Plots/BCsplit_stats.pdf',myplot,width = 2.5,height = 4)

      # Pipeline stats

        # HQ Aligns
        mydt <- fread('Logs/Alignment_hq_stats.txt',
                    col.names=c('file', 'HQ_algs'))
        mydt[,file:=dirname(file)]

        # Dedup Aligns
        dt <- fread('Logs/Alignment_dedup_stats.txt',
                    col.names=c('file', 'Dedup_algs'))
        dt[,file:=dirname(file)]
        mydt <- merge(mydt,dt, by='file')

        # Discarded alignments
        dt <- fread('Logs/alignment_multimap_stats.txt',col.names=c('file', 'N','MAPQ'))
        dt <-  dt[,.(Multimappers=sum(N[MAPQ < 50])), by=.(file)]
        mydt <- merge(mydt,dt, by='file')

        # rRNA cleanup
        dt <- fread('Logs/RNA_cleup_stats.txt')
        mydt <- merge(mydt,dt, by='file')

        # Fix file name
        mydt[,file:= gsub('run_umi_(.*)_umied',"\\1",file)]

        # Add initial reads (after bc split)
        dt <- fread('Logs/bc_split_stats.txt',fill=T,select = c('Barcode','Count'))
        dt <- dt[1:(nrow(dt) -2)]
        colnames(dt) <- c('file','Initial_reads')
        mydt <- merge(mydt,dt, by='file')

        # Create stats
        mysum <- mydt[,.(
          'file'=file,
          'rRNA_reads'= Initial_reads - rrnaleft,
          'tRNA_reads' = rrnaleft - trnaleft,
          'Multimapper_reads' = Multimappers,
          'Other_causes'= trnaleft - HQ_algs - Multimappers,
          'Dup_HQalgs' = HQ_algs - Dedup_algs,
          'Uniq_HQals' = Dedup_algs)]

        # Check
        rowSums(mysum[,-1]) == mydt$Initial_reads # True

        # Arrange and save
        mysum <- melt(mysum,id.vars='file')
        write.table(mysum, 'Logs/Diricore_stats.txt',sep='\t',
                    quote=F, row.names=F)

        # Plot
        myplot <- ggplot(mysum, aes(x=file, y=value/1000000,fill=variable))
        myplot <- myplot + geom_bar(stat='identity')+
          theme_bw(8) + coord_flip() + ylab('Million reads') + xlab(NULL)
        myplot
        ggsave('Plots/Diricore_stats.pdf',myplot,width = 5, height = 3)
      ````


  ### Generate tracks
    #### Calculate coverage
      ````bash
      bam_to_bw(){
      hg19="/home/jandrulas/Genome_Data/hg19/UCSC/hg19.chrom.sizes"
      inf="data/output/tophat_out/${1}/accepted_hits.hqmapped_dedup.bam"
      echo "Calculating normalization factor for ${1}]"
      fact=$(samtools view -c $inf) &&
      fact=$(echo "scale=6; 1000000.0 / $fact" | bc)
      echo "Done: ${fact}. Writing bdg files"
      samtools view -b $inf | tee \
      >(bedtools genomecov -ibam /dev/stdin -g $hg19 -scale $fact -bg -split -strand + \
      | sort -k1,1 -k2,2n > ${2}_plus.bdg) \
      | bedtools genomecov -ibam /dev/stdin -g $hg19 -scale $fact -bg -split -strand - |
      sort -k1,1 -k2,2n > ${2}_minus.bdg
      }
      # Generate bedgraph
      export -f bam_to_bw
      cat data/input/metadata/rpf_density_samplenames.tsv \
      | while read -a line; do
        bam_to_bw ${line[@]}
      done

      # Convert to bigwig
      hg19="/home/jandrulas/Genome_Data/hg19/UCSC/hg19.chrom.sizes"
      parallel bedGraphToBigWig {} $hg19 {.}.bw ::: *.bdg
      ````
    #### Generate trackDB

      ````bash
      echo -e "
      track run_UMIs
      superTrack on show
      shortLabel run_UMIs
      longLabel run_UMIs
      html ../track_help.html
      autoScale On
      yLineOnOff on
      alwaysZero on
      " > UCSC_TrackDb.txt

      for i in Control CDK1in C Ha Roca HaRoca; do
      echo -e "
      \ttrack $i
      \tparent run_UMIs
      \tcontainer multiWig
      \tshortLabel $i
      \tlongLabel $i
      \ttype bigWig
      \taggregate solidOverlay
      \tshowSubtrackColorOnUi on
      \tvisibility full
      \tmaxHeightPixels 100:40:10

      \t\ttrack ${i}_plus.bw
      \t\tbigDataUrl run_UMIs/${i}_plus.bw
      \t\tparent $i
      \t\ttype bigWig
      \t\tshortLabel ${i}_+
      \t\tLongLabel ${i}_+
      \t\tcolor 19,80,181

      \t\ttrack ${i}_minus.bw
      \t\tbigDataUrl run_UMIs/${i}_minus.bw
      \t\tparent $i
      \t\ttype bigWig
      \t\tshortLabel ${i}_-
      \t\tLongLabel ${i}_-
      \t\tnegateValues on
      \t\taltColor 206,58,0

      \t\t####################################
      "
      done >> UCSC_TrackDb.txt
      ````

  ### Find the top rRNA fragments for substraction
````bash
  RRNA_REF="staticdata/human/rRNAs"
  zcat data/input/fastq/*.fastq.gz \
  | ./programs/bowtie2-2.0.6/bowtie2 --seed 42 -p 1 --local  "${RRNA_REF}" - \
  | samtools view -F 0x4 \
  | awk '{print $10}' \
  | sort | uniq -c | awk '$1 > 100000 {print $1,$2}' \
  | sort -k1nr \
  > ~/Fabricio/20190123_run/rRNA_analysis/run_UMIs_top_rRNA_seqs.txt
````
  ````r
  require(data.table)
  require(Biostrings)
  require(ggplot2)
  dt <- fread('run_UMIs_top_rRNA_seqs.txt',col.names=c('Counts','Seq'))


  Group the sequences using pairwiseAlignment( more flexible)
   seqs <- DNAStringSet(unique(dt$Seq))
   seqs <- seqs[order(width(seqs))]
   mylist <- list()
   while (length(seqs) > 0){
     p <- pairwiseAlignment(seqs, seqs[[length(seqs)]])
     id <- nmatch(p) / width(seqs) # calculate percentaje of identity
     g <- nmismatch(p) == 0 & id > 0.7
     mylist[as.character(seqs[[length(seqs)]])] <- list(as.character(seqs[g]))
     seqs <- seqs[!g]
     }
   mygroups <- data.table(Group = unlist(sapply(1:length(mylist), function(x) rep(names(mylist[x]), length(mylist[[x]])))), Seq = unlist(mylist))

 # Add group info to counts table
   mysum <- merge(dt,mygroups, by='Seq')
   mysum[,Counts_grouped:=sum(Counts),by=.(Group)]
   write.table(mysum[order(-Counts_grouped)], 'run_UMIs_top_rRNA_seqs_grouped.txt', sep='\t', quote=F,row.names=F)


### RPF transcript distribution barplot

I have made a script to count reads in transcript features. The script was adapted from the original plot_rpf_transcript_distribution. It keeps the initial step to select the representative transcripts of each gene and most of the function that fetch the counts for each transcript. However, this script does not interpolate or anything, it just calculate the counts in each defined region. The counts are then transform to percentage and then averaged by sample after filtering by minimum reads. The scripts outputs the calculated average percentage of reads in each region, per sample. In addition, it generates a similar file with the counts normalized by length. For this normalization, the counts per regions are transform to counts per kilobase (counts * 1000 / region length) and the normalize by the sum of all regions.

  ````bash
  # Run the script (called from a bash wrapper)
  ./barplot_rpf_transcript_distribution.sh 20190123_Umi 100 hola
  ````

  Make a the plot in R:

  ````r
  setwd('Uniovi_new/Fabricio/20190123_run/')
  require(data.table)
  require(ggplot2)

  mydt1 <- fread('Counts/20190123_Umi.rpf_in_regs.hola.txt')
  mydt2 <- fread('Counts/20190123_Umi.rpf_in_regs.holanorm.txt')

  mydt1[,Type:='Counts']
  mydt2[,Type:='RPK']

  mydt <- rbind(mydt1,mydt2)

  mydt[,Sample:= gsub('run_umi_(.*)_umied',"\\1",Sample)]
  mysum <- melt(mydt, id.vars=c('Sample','Type'))
  myplot <- ggplot(mysum, aes(x=Sample, y=value, fill=variable))
  myplot <- myplot + geom_bar(stat='identity', position='stack',width=0.8) + theme_bw() +
    ylab('Average % of reads') + xlab(NULL) + facet_wrap(~Type)
  myplot
  ggsave('Plots/rpf_transcript_distribution/20190123_Umi_rpf_in_regs.pdf',myplot)
  ````


## Archive data
````bash
tar -cvf ~/Fabricio/run_UMIs_Alignments.tar output/tophat_out/*/accepted_hits.hqmapped*
tar -cvf ~/Fabricio/run_UMIs_subsequence_data.tar output/subsequence_data/*hdf5
tar -cvf ~/Fabricio/run_UMIs_rpf_5p_density.tar output/rpf_5p_density/*hdf5
tar -cvf ~/Fabricio/run_UMIs_diri_meta.tar input/metadata/
tar -cvf 20190123_runUMIs_Fabricio.tar *.tar
scp 20190123_runUMIs_Fabricio.tar 156.35.56.78:/home/jandrulas/mydata/pending_of_removal/
````
